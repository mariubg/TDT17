{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task a) Compute $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to perform the convolution. We call the output of the convolutional layer $CN$:\n",
    "\n",
    "$$\\begin{align}CN  & = X \\circledast F^C - B^C\\\\\n",
    "\n",
    "& = \\begin{bmatrix}\n",
    "0 & 3 & -1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 3 & 0 \\\\\n",
    "3 & 0 & 3 & 1\n",
    "\\end{bmatrix} \\circledast\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "-1 & 0 \\\\\n",
    "\\end{bmatrix} -1\\\\\n",
    "\n",
    "& = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "-2 & 1\n",
    "\\end{bmatrix}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put this matrix through the self-attention layer. \n",
    "\n",
    "First we calculate the query, key and value matrices:\n",
    "$$\n",
    "Q = CN * W^Q\n",
    "= \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "-2 & 1 \\\\\n",
    "\\end{bmatrix} *\n",
    "\\begin{bmatrix}\n",
    "1 & -2 \\\\\n",
    "0 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "1 & -2 \\\\\n",
    "-2 & 6 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "K = CN * W^K\n",
    "= \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "-2 & 1 \\\\\n",
    "\\end{bmatrix} *\n",
    "\\begin{bmatrix}\n",
    "1 & -1 \\\\\n",
    "3 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "1 & -1 \\\\\n",
    "1 & 2 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "V = CN * W^V\n",
    "= \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "-2 & 1 \\\\\n",
    "\\end{bmatrix} *\n",
    "\\begin{bmatrix}\n",
    "3 & 1 \\\\\n",
    "-1 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "3 & 1 \\\\\n",
    "-7 & -1 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "$$\n",
    "\n",
    "The output of the self-attention layer is:\n",
    "$$SA = softmax(\\frac{Q * K^T}{\\sqrt{d}})* V$$\n",
    "\n",
    "d is the size of dimaensions of each query, in this network 2. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "SA & = softmax(\\frac{\n",
    "\\begin{bmatrix}\n",
    "1 & -2 \\\\\n",
    "-2 & 6 \\\\\n",
    "\\end{bmatrix}\n",
    "*\n",
    "\\begin{bmatrix}\n",
    "1 & -1 \\\\\n",
    "1 & 2 \\\\\n",
    "\\end{bmatrix}^T\n",
    "}{\\sqrt{2}})*\n",
    "\\begin{bmatrix}\n",
    "3 & 1 \\\\\n",
    "-7 & -1 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "\n",
    "& = softmax(\\frac{\n",
    "\\begin{bmatrix}\n",
    "1 & -2 \\\\\n",
    "-2 & 6 \\\\\n",
    "\\end{bmatrix}\n",
    "*\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "-1 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "}{\\sqrt{2}})*\n",
    "\\begin{bmatrix}\n",
    "3 & 1 \\\\\n",
    "-7 & -1 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "\n",
    "& = softmax(\\begin{bmatrix}\n",
    "-\\frac{1}{\\sqrt{2}} & -\\frac{5}{\\sqrt{2}} \\\\\n",
    "2\\cdot\\sqrt{2} & 7\\cdot\\sqrt{2} \\\\\n",
    "\\end{bmatrix})*\n",
    "\\begin{bmatrix}\n",
    "3 & 1 \\\\\n",
    "-7 & -1 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "\n",
    "& = \\begin{bmatrix}\n",
    "0.03 & 0 \\\\\n",
    "0.97 & 1 \\\\\n",
    "\\end{bmatrix}*\n",
    "\\begin{bmatrix}\n",
    "3 & 1 \\\\\n",
    "-7 & -1 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "\n",
    "& = \\begin{bmatrix}\n",
    "0.09 & 0.03 \\\\\n",
    "-4.09 & 1.97 \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\end{align}$$\n",
    "\n",
    "Now we flatten this so that $SA = \\begin{bmatrix}\n",
    "0.09\\\\\n",
    "0.03\\\\\n",
    "-4.09\\\\\n",
    "1.97\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Finally, we calculate $\\hat{y}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{y} & = ReLU(W^{DT}* SA -B^D)\\\\\n",
    "& = ReLU(\\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "2\\\\\n",
    "\\end{bmatrix}^T * \\begin{bmatrix}\n",
    "0.09\\\\\n",
    "0.03\\\\\n",
    "-4.09\\\\\n",
    "1.97\\\\\n",
    "\\end{bmatrix} - 1)\\\\\n",
    "& = ReLU(\\begin{bmatrix}\n",
    "1 & 1 & 0 & 2\\\\\n",
    "\\end{bmatrix}*\\begin{bmatrix}\n",
    "0.09\\\\\n",
    "0.03\\\\\n",
    "-4.09\\\\\n",
    "1.97\\\\\n",
    "\\end{bmatrix} - 1)\\\\\n",
    "\n",
    "& = ReLU(3.06)\\\\\n",
    "\n",
    "& = \\underline{\\underline{3.06}}\n",
    "\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task b) Update the weights and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we calculate the derivative of the error:\n",
    "$$\\frac{\\partial C}{\\partial \\hat{y}} = 2(y-\\hat{y}) = -4.12$$\n",
    "\n",
    "To update the weights and biases of the FCNN, we propagate it back:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial W^D} & = \\frac{\\partial C}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial W^D}\\\\\n",
    "& = 2(y-\\hat{y})\\cdot SA\n",
    "& = -4.12 \\cdot \\begin{bmatrix}\n",
    "0.09\\\\\n",
    "0.03\\\\\n",
    "-4.09\\\\\n",
    "1.97\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "-0.37\\\\\n",
    "-0.12\\\\\n",
    "16.85\\\\\n",
    "-8.12\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial B^D} = \\frac{\\partial C}{\\partial \\hat{y}} = -4.12\n",
    "$$\n",
    "\n",
    "We can now update $W^D$ and $B^D$:\n",
    "\n",
    "$$\n",
    "W_1^D = W_0^D -\\alpha\\frac{\\partial C}{\\partial W^D} = \\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "2\\\\\n",
    "\\end{bmatrix} - 0.1\n",
    "\\begin{bmatrix}\n",
    "-0.37\\\\\n",
    "-0.12\\\\\n",
    "16.85\\\\\n",
    "-8.12\\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "1.04\\\\\n",
    "1.01\\\\\n",
    "-1.69\\\\\n",
    "2.812\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "B_1^D = B_0^D - \\alpha\\frac{\\partial C}{\\partial B^D} = -1 - 0.1\\cdot -4.12 = 0.59\n",
    "$$\n",
    "\n",
    "In order to calculate the derivatives for the other layers, we also need:\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial C}{\\partial SA} & = \\frac{\\partial C}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial SA}\\\\\n",
    "& = 2(y-\\hat{y}) \\cdot W^D\n",
    "& = -4.12 \\cdot \\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "2\\\\\n",
    "\\end{bmatrix} \\\\\n",
    "& = \\begin{bmatrix}\n",
    "-4.12\\\\\n",
    "-4.12\\\\\n",
    "0\\\\\n",
    "-8.24\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We reshape this to: $\\frac{\\partial C}{\\partial SA} = \\begin{bmatrix}\n",
    "-4.12 & -4.12\\\\\n",
    "0 & -8.24\\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation through the self-attention layer is a bit more complicated. In order to make it more readable, we call $\\frac{Q* K^T}{\\sqrt{d}}$ $S$, and $softmax(S)$ $A$, so that $SA = A* V = softmax(S)*V$. Then we have:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial V} & = A^T * \\frac{\\partial C}{\\partial SA}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "0.03 & 0.97 \\\\\n",
    "0 & 1 \\\\\n",
    "\\end{bmatrix} * \\begin{bmatrix}\n",
    "-4.12 & -4.12\\\\\n",
    "0 & -8.24\\\\\n",
    "\\end{bmatrix}\n",
    "& = \\begin{bmatrix}\n",
    "-0.12 & -8.12\\\\\n",
    "0 & -8.24\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This can be used to calculate the derivatives of the cost wrt the values weights:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial C}{\\partial W^V} & = CN^T * \\frac{\\partial C}{\\partial V}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "1 & -2\\\\\n",
    "0 & 1\\\\\n",
    "\\end{bmatrix} * \\begin{bmatrix}\n",
    "-0.12 & -8.12\\\\\n",
    "0 & -8.24\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "-0.12 & 8.36\\\\\n",
    "0 & -8.24\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Now we update the value weights:\n",
    "$$\n",
    "W_1^V = W_0^V - \\alpha\\cdot\\frac{\\partial C}{\\partial W^V} = \n",
    "\\begin{bmatrix}\n",
    "3.01 & 0.17\\\\\n",
    "-1 & 1.82\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We also have \n",
    "$$\\begin{align}\n",
    "\\frac{\\partial C}{\\partial A} & = \\frac{\\partial C}{\\partial SA} * V^T\\\\\n",
    "& = \\begin{bmatrix}\n",
    "-4.12 & -4.12\\\\\n",
    "0 & -8.24\\\\\n",
    "\\end{bmatrix} *\n",
    "\\begin{bmatrix}\n",
    "3 & -7\\\\\n",
    "1 & 1\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "& \\begin{bmatrix}\n",
    "-16.48 & 24.72\\\\\n",
    "-8.24 & -8.24\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In order to find the derivatives wrt the query and key weights, we need to derivate the softmax function. This is easier if we split the matrix into two serparate rows. We have:\n",
    "$A_1 = [0.03, 0.97]$ and $A_2 = [0, 1]$, as well as $\\frac{\\partial C}{\\partial A_1} = [-16.48, -8.24]$, $\\frac{\\partial C}{\\partial A_2} = [24.72, -8.24]$, $S_1 = [-\\frac{1}{\\sqrt{2}}, 2\\sqrt{2}]$ and $S_2 = [-\\frac{5}{\\sqrt{2}}, 7\\sqrt{2}]$. The Jacobian for a softmax function used on a 2x2 matrix is:\n",
    "$$J_{softmax} = \\begin{bmatrix}\n",
    "a_1\\cdot(1-a_1) & -a_1\\cdot a_2\\\\\n",
    "-a_2 \\cdot a_1 & a_2\\cdot (1-a_2)\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Since $1-a_1 =a_2 $, we can simply calculate $a1\\cdot a_2$ and insert this, and get $\\frac{\\partial A_1}{\\partial S_1}$ and $\\frac{\\partial A_2}{\\partial S_2}$\n",
    "Then\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial S_1} & = \\frac{\\partial A_1}{\\partial S_1} * \\frac{\\partial C}{\\partial A_1}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "0.29 & 0.29\\\\\n",
    "0.29 & 0.29\\\\\n",
    "\\end{bmatrix} * \n",
    "\\begin{bmatrix}\n",
    "-16.48\\\\\n",
    "-8.24\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "-7.17 & -7.17\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since the first element in $A_2$ is $0$, $\\frac{\\partial C}{\\partial S_2} = [0, 0]$ Putting these together, we get $\\frac{\\partial C}{\\partial S} = \\begin{bmatrix}-7.17 & 0\\\\ -7.17 & 0\\end{bmatrix}$\n",
    "\n",
    "Now we can calcualte the derivative for the query:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial Q} & = \\frac{1}{\\sqrt{d}} * \\frac{\\partial C}{\\partial S} * K\\\\\n",
    "&  = \\frac{1}{\\sqrt{2}} * \\begin{bmatrix}\n",
    "-7.17 & 0\\\\\n",
    "-7.17 & 0\\\\\n",
    "\\end{bmatrix} * \n",
    "\\begin{bmatrix}\n",
    "1 & -1\\\\\n",
    "1 & 2 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "-5.07 & 5.07\\\\\n",
    "-5.07 & 5.07\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And for the query weights:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial W^Q} & = CN^T * \\frac{\\partial C}{\\partial Q}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "1 & -2\\\\\n",
    "0 & 1\\\\\n",
    "\\end{bmatrix}*\n",
    "\\begin{bmatrix}\n",
    "-5.07 & 5.07\\\\\n",
    "-5.07 & 5.07\\\\\n",
    "\\end{bmatrix} \\\\\n",
    "& = \\begin{bmatrix}\n",
    "5.07 & -5.07\\\\\n",
    "-5.07 & 5.07\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And for the key:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial K} & = \\frac{1}{\\sqrt{d}} *Q^T * \\frac{\\partial C}{\\partial S}\\\\\n",
    "&  = \\frac{1}{\\sqrt{2}} * \\begin{bmatrix}\n",
    "1 & -2\\\\\n",
    "-2 & 6\\\\\n",
    "\\end{bmatrix} * \n",
    "\\begin{bmatrix}\n",
    "-7.17 & 0\\\\\n",
    "-7.17 & 0\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "5.07 & 0\\\\\n",
    "-20.28 & 0\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial W^K} & = CN^T * \\frac{\\partial C}{\\partial K}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "1 & -2\\\\\n",
    "0 & 1\\\\\n",
    "\\end{bmatrix}*\n",
    "\\begin{bmatrix}\n",
    "5.07 & 0\\\\\n",
    "-20.28 & 0\\\\\n",
    "\\end{bmatrix} \\\\\n",
    "& = \\begin{bmatrix}\n",
    "45.63 & 0\\\\\n",
    "-20.28 & 0\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Using these to update the weights, we get: $W_1^Q = \\begin{bmatrix}0.49 & -1.49\\\\ 0.51 & 1.49\\\\ \\end{bmatrix}$ and $W_1^K = \\begin{bmatrix}-3.56 & -1\\\\ 5.03 & 0\\\\ \\end{bmatrix}$\n",
    "\n",
    "Finally, we find $\\frac{\\partial C}{\\partial CN}$ by combining the gradients from the query, key and values:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial CN} & = \\frac{\\partial C}{\\partial Q} * W^{QT} +\\frac{\\partial C}{\\partial K} * W^{KT} + \\frac{\\partial C}{\\partial V} * W^{VT}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "-5.07 & 5.07\\\\\n",
    "-5.07 & 5.07\\\\\n",
    "\\end{bmatrix}*\n",
    "\\begin{bmatrix}\n",
    "1 & 0\\\\\n",
    "-2 & 2\\\\\n",
    "\\end{bmatrix} +\n",
    "\\begin{bmatrix}\n",
    "5.07 & 0\\\\\n",
    "-20.28 & 0\\\\\n",
    "\\end{bmatrix}*\n",
    "\\begin{bmatrix}\n",
    "1 & 3\\\\\n",
    "-1 & 0\\\\\n",
    "\\end{bmatrix}+\n",
    "\\begin{bmatrix}\n",
    "-0.12 & -8.12\\\\\n",
    "0 & -8.24\\\\\n",
    "\\end{bmatrix}*\n",
    "\\begin{bmatrix}\n",
    "3 & -1\\\\\n",
    "1 & 1\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "-15.21 & 10.14\\\\\n",
    "-15.21 & 10.14\\\\\n",
    "\\end{bmatrix}+\n",
    "\\begin{bmatrix}\n",
    "5.07 & 15.21\\\\\n",
    "-20.28 & -60.84\\\\\n",
    "\\end{bmatrix}+\n",
    "\\begin{bmatrix}\n",
    "-8.48 & -8\\\\\n",
    "-8.24 & 8.24\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "& = \\begin{bmatrix}\n",
    "-18.62 & 17.35\\\\\n",
    "-43.73 & -42.46\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
