{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have following architecture:\n",
    "\n",
    "![Architecture](architecture.png \"Architecture\")\n",
    "\n",
    "The input is $$X = \\begin{bmatrix}\n",
    "0 & 3 & -3 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 3 & 0 \\\\\n",
    "3 & 0 & 3 & 1 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "The convolutional layer has the filter $F^C = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "-1 & 0\n",
    "\\end{bmatrix}$ and bias $B^C = 1$. The padding is 0, and the stride is 2. This layer has a linear activation function.\n",
    "\n",
    "The self-attention layer has three weight matrices creating queries, keys and values:\n",
    "$$W^Q =\\begin{bmatrix}\n",
    "1 & -2  \\\\\n",
    "0 & 2  \\\\\n",
    "\n",
    "\\end{bmatrix},\n",
    "W^K = \\begin{bmatrix}\n",
    "1 & -1 \\\\\n",
    "3 & 0 \\\\\n",
    "\n",
    "\\end{bmatrix},\n",
    "W^V = \\begin{bmatrix}\n",
    "3 & 1\\\\\n",
    "-1 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The FCNN has the weights $W^D = [1,  -1, 0,2,]$ and the bias $B^D = -1$. This layer uses ReLU as its activation function.\n",
    "\n",
    "The target is $y = 1$, and the loss function is $C = \\frac{1}{N} * \\sum_{n=1}^{N} (y_i-\\hat{y_i})^2$, or MSE. The learning rate is $\\alpha = 0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Compute the remaining values in the output of the convolutional layer:\n",
    "$$CN = \\begin{bmatrix}\n",
    "\\phantom{1} & 0 \\\\\n",
    "\\phantom{-2} & 1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "b) Compute the remaining values in the output of the self-attention layer:\n",
    "$$SA = \\begin{bmatrix}\n",
    "0.09 & \\phantom{0.03} \\\\\n",
    "\\phantom{-4.09} & 1.97 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "c) Compute $\\hat{y}$\n",
    "\n",
    "d) Find the updated weights and biases of the fully connected layer, $W_1^D$ and $B_1^D$\n",
    "\n",
    "$$W_1^D = \\begin{bmatrix}\n",
    "\\phantom{1.04}\\\\\n",
    "1.01\\\\\n",
    "\\phantom{-1.69}\\\\\n",
    "2.812\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$B_1^D = $$\n",
    "\n",
    "e) Find the updated weights of the self-attention layer:\n",
    "\n",
    "$$W_1^Q = \\begin{bmatrix}\\phantom{0.49} & -1.49\\\\ 0.51 & 1.49\\\\ \\end{bmatrix}$$\n",
    "$$W_1^K = \\begin{bmatrix}-3.56 & -1\\\\ \\phantom{5.03} & 0\\\\ \\end{bmatrix}$$\n",
    "\n",
    "$$W_1^V = \\begin{bmatrix}\n",
    "\\phantom{3.01} & 0.17\\\\\n",
    "-1 & 1.82\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "f) Find the updated filter of the convolutional layer:\n",
    "\n",
    "$$F_1^C = \\begin{bmatrix}-4.21 & -1.86\\\\\\phantom{12.12} & 19.65\\\\\\end{bmatrix}$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
